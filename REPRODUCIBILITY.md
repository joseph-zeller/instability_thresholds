Reproducibility Guide



This document describes how to reproduce all analyses, figures, and Supplementary Information tables reported in:



Threshold Instability in Large-Scale Human Systems: Quantitative Evidence for Collapse Beyond Extreme Complexity



All results can be regenerated from the provided datasets using the scripts in this repository.



1\. Computational Environment



All analyses were executed using Python (≥3.10).



A complete environment specification is provided.



Create environment

conda env create -f environment.yml

conda activate instability\_thresholds



2\. Data Inputs



All cleaned datasets used in the manuscript are located in:



data/final/





These include:



seshat\_EI\_collapse\_panel\_w100.csv



SPC1\_collapse\_panel\_w100.csv



merged cross-predictor panels used for convergence tests



No external downloads are required.



3\. Full Reproduction Pipeline



To reproduce all analyses, tables, and figures:



python src/run\_all.py





This script executes:



Threshold estimation models



Cross-validated performance metrics



Robustness analyses



Permutation convergence tests



Figure generation



Supplementary Information table creation



All outputs are written to:



results/

figures/

output/tables/



4\. Supplementary Information Tables



Each SI table is generated by an independent script for transparency.



To regenerate all tables:



python src/tables/make\_all\_tables.py





Individual tables can be regenerated as:



python src/tables/make\_table\_S1\_pca\_complexity.py

python src/tables/make\_table\_S2\_core\_thresholds.py

python src/tables/make\_table\_S3\_eta\_exclusions.py

python src/tables/make\_table\_S4\_SPC1\_horizons.py

python src/tables/make\_table\_S5\_eta\_horizons.py

python src/tables/make\_table\_S6\_population\_strata.py

python src/tables/make\_table\_S7\_cross\_predictor\_convergence.py





Outputs are written to:



output/tables/





in both CSV and Markdown formats.



5\. Randomness and Determinism



All stochastic components (cross-validation splits, permutation tests) are executed with fixed random seeds to ensure bitwise reproducibility.



Permutation convergence tests use:



N = 100,000





as reported in the manuscript.



6\. Expected Runtime



On a standard laptop:



Component	Approximate runtime

Full pipeline	2–5 minutes

Permutation tests	~1 minute

Table generation	<10 seconds

7\. Verification



Successful reproduction should yield:



Identical threshold percentiles across predictors



AUC values matching those reported in SI tables



Convergent upper-tail instability regimes across robustness checks



Minor floating-point variation (<1e-6) may occur across systems.



8\. Reproducibility Philosophy



This repository is designed to ensure:



✔ No hidden preprocessing

✔ No manual intervention

✔ Transparent threshold localisation

✔ Independent verification of robustness claims



All manuscript claims are directly traceable to executable code.

